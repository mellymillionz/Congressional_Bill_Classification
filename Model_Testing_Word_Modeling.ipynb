{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Testing** - Word Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All Features:**\n",
    "\n",
    "Data columns (total 29 columns):\n",
    "\n",
    "Specific Identifiers:\n",
    "\n",
    "- BillID      51067 non-null object\n",
    "\n",
    "\n",
    "How far it made it:\n",
    "\n",
    "- PassH       51067 non-null int64\n",
    "- PassS       51067 non-null int64\n",
    "- PLawDate    1393 non-null object - MAKE BOOL?\n",
    "- PLawNum     51067 non-null object\n",
    "- PLaw        51067 non-null int64\n",
    "- Veto        51067 non-null int64\n",
    "\n",
    "Bill Descriptive Info:\n",
    "\n",
    "- BillType    51067 non-null object\n",
    "- Title       51067 non-null object\n",
    "- Cong        51067 non-null int64\n",
    "- Summary     51017 non-null object - REMOVE NULL\n",
    "- ImpBill     51067 non-null int64\n",
    "- Chamber     51067 non-null int64 (H or S)\n",
    "\n",
    "Info about Rep Bill Proposer:\n",
    "\n",
    "- Cosponsr    51067 non-null float64\n",
    "- IntrDate    51025 non-null object - REMOVE NULL\n",
    "- Mult        51067 non-null int64\n",
    "- Class       51067 non-null float64\n",
    "- District    51067 non-null float64\n",
    "- FrstConH    51067 non-null float64\n",
    "- FrstConS    51067 non-null float64\n",
    "- Gender      51067 non-null int64\n",
    "- MRef        51067 non-null int64\n",
    "- NameFull    51067 non-null object\n",
    "- Party       51067 non-null float64\n",
    "- Postal      51067 non-null object\n",
    "- Majority    51067 non-null int64\n",
    "\n",
    "Other general bill info:\n",
    "\n",
    "- Major       51067 non-null float64\n",
    "- Minor       51067 non-null float64\n",
    "\n",
    "The URL:\n",
    "\n",
    "- URL         51067 non-null object\n",
    "\n",
    "\n",
    "List of the models to test and the parameters to tune:\n",
    "  \n",
    "**Models:**\n",
    "- Naive Bayes\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- SVM\n",
    "\n",
    "**Evaluations:**\n",
    "- Accuracy, precision, recall, f1\n",
    "- Confusion Matrix\n",
    "- ROC/AUC\n",
    "\n",
    "**Class Imbalance Issues:**\n",
    "- Run a model on just one topic with good class distribution:\n",
    "- Undersampling\n",
    "- Use top 10 words for each PassH as features\n",
    "\n",
    "\n",
    "- try running models with only words\n",
    "- ADD top five pass, top five not pass\n",
    "\n",
    "\n",
    "- try one without 112th\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Query Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: sentence-transformers in /Users/melissamunz/anaconda3/lib/python3.7/site-packages (0.2.5)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /Users/melissamunz/anaconda3/lib/python3.7/site-packages (from sentence-transformers) (1.16.4)\n",
      "Requirement already satisfied, skipping upgrade: nltk in /Users/melissamunz/.local/lib/python3.7/site-packages (from sentence-transformers) (3.4.5)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /Users/melissamunz/anaconda3/lib/python3.7/site-packages (from sentence-transformers) (0.22)\n",
      "Requirement already satisfied, skipping upgrade: transformers==2.3.0 in /Users/melissamunz/anaconda3/lib/python3.7/site-packages (from sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /Users/melissamunz/anaconda3/lib/python3.7/site-packages (from sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: torch>=1.0.1 in /Users/melissamunz/anaconda3/lib/python3.7/site-packages (from sentence-transformers) (1.4.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /Users/melissamunz/anaconda3/lib/python3.7/site-packages (from sentence-transformers) (4.32.1)\n",
      "Requirement already satisfied, skipping upgrade: six in /Users/melissamunz/anaconda3/lib/python3.7/site-packages (from nltk->sentence-transformers) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /Users/melissamunz/anaconda3/lib/python3.7/site-packages (from scikit-learn->sentence-transformers) (0.13.2)\n",
      "Requirement already satisfied, skipping upgrade: sacremoses in /Users/melissamunz/anaconda3/lib/python3.7/site-packages (from transformers==2.3.0->sentence-transformers) (0.0.38)\n",
      "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /Users/melissamunz/anaconda3/lib/python3.7/site-packages (from transformers==2.3.0->sentence-transformers) (2020.1.8)\n",
      "Requirement already satisfied, skipping upgrade: requests in /Users/melissamunz/anaconda3/lib/python3.7/site-packages (from transformers==2.3.0->sentence-transformers) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: sentencepiece in /Users/melissamunz/anaconda3/lib/python3.7/site-packages (from transformers==2.3.0->sentence-transformers) (0.1.85)\n",
      "Requirement already satisfied, skipping upgrade: boto3 in /Users/melissamunz/anaconda3/lib/python3.7/site-packages (from transformers==2.3.0->sentence-transformers) (1.11.5)\n",
      "Requirement already satisfied, skipping upgrade: click in /Users/melissamunz/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers==2.3.0->sentence-transformers) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/melissamunz/anaconda3/lib/python3.7/site-packages (from requests->transformers==2.3.0->sentence-transformers) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /Users/melissamunz/anaconda3/lib/python3.7/site-packages (from requests->transformers==2.3.0->sentence-transformers) (2019.6.16)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /Users/melissamunz/anaconda3/lib/python3.7/site-packages (from requests->transformers==2.3.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /Users/melissamunz/anaconda3/lib/python3.7/site-packages (from requests->transformers==2.3.0->sentence-transformers) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /Users/melissamunz/anaconda3/lib/python3.7/site-packages (from boto3->transformers==2.3.0->sentence-transformers) (0.9.4)\n",
      "Requirement already satisfied, skipping upgrade: botocore<1.15.0,>=1.14.5 in /Users/melissamunz/anaconda3/lib/python3.7/site-packages (from boto3->transformers==2.3.0->sentence-transformers) (1.14.5)\n",
      "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /Users/melissamunz/anaconda3/lib/python3.7/site-packages (from boto3->transformers==2.3.0->sentence-transformers) (0.3.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /Users/melissamunz/anaconda3/lib/python3.7/site-packages (from botocore<1.15.0,>=1.14.5->boto3->transformers==2.3.0->sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /Users/melissamunz/anaconda3/lib/python3.7/site-packages (from botocore<1.15.0,>=1.14.5->boto3->transformers==2.3.0->sentence-transformers) (0.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from sodapy import Socrata\n",
    "import sqlalchemy as db\n",
    "\n",
    "import config_final as config\n",
    "from schema import DbSchema\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bills_db = DbSchema(config)\n",
    "\n",
    "# topics_db = bills_db.query('SELECT * from topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>PassH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To provide for the implementation of the recom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reserved for Speaker.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To amend the Higher Education Act of 1965 to p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To award a congressional gold medal to Edward ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To amend the Haitian Hemispheric Opportunity t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  PassH\n",
       "0  To provide for the implementation of the recom...      1\n",
       "1                              Reserved for Speaker.      0\n",
       "2  To amend the Higher Education Act of 1965 to p...      0\n",
       "3  To award a congressional gold medal to Edward ...      0\n",
       "4  To amend the Haitian Hemispheric Opportunity t...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Query all titles and Passing\n",
    "\n",
    "df = bills_db.query(\"\"\"\n",
    "    SELECT\n",
    "        cb.Title,\n",
    "        cb.PassH\n",
    "    FROM con_bills.current_bills as cb\n",
    "    JOIN con_bills.topics as tp\n",
    "    ON cb.BillID = tp.BillID\n",
    "    WHERE cb.Cong >=110\n",
    "    \"\"\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51067, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(['dominant_topic', 'PassH']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PassH'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tokenizer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "import en_core_web_sm\n",
    "import string\n",
    "import re\n",
    "\n",
    "def tokenizer(text):\n",
    "    \n",
    "    nlp = English()\n",
    "\n",
    "    stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "    nlp.Defaults.stop_words |= {\"bill\",\"amend\", \"purpose\", \"united\", \"state\", \"states\", \"secretary\", \"act\", \"federal\", \"provide\"}\n",
    "\n",
    "    replace_with_space = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "\n",
    "    just_words = re.compile('[^a-zA-Z\\s]')\n",
    "\n",
    "    # Create our list of punctuation marks\n",
    "    punctuations = string.punctuation\n",
    "\n",
    "    # Create our list of stopwords\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "    stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "    \n",
    "    #lowercase everything\n",
    "    lower_text = text.lower()\n",
    "    \n",
    "    #remove punctuation\n",
    "#     no_pun_text = lower_text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    #get rid of weird characters\n",
    "    text = replace_with_space.sub('',lower_text)\n",
    "    \n",
    "    #remove numbers\n",
    "    just_words_text = just_words.sub('', text)\n",
    "    \n",
    "    #add spacy tokenizer\n",
    "    mytokens = nlp(just_words_text, disable=['parser', 'ner'])\n",
    "#     print(mytokens)\n",
    "    \n",
    "    #for POS tagging\n",
    "#     mytokens = [word for word in mytokens if (word.pos_ == 'NOUN') or (word.pos_ == 'VERB') or (word.pos_ == 'ADJ') or (word.pos_ == 'ADV')]\n",
    "    \n",
    "    #lemmatize\n",
    "    mytokens = [word.lemma_.strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "    \n",
    "    #MAP SPECIFIC WORDS to others (veteran from veterans)\n",
    "\n",
    "    #add stopwords\n",
    "    mytokens = [word for word in mytokens if word not in stop_words and word not in punctuations]\n",
    "    \n",
    "    return mytokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>PassH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[implementation, recommendation, national, com...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[implementation, recommendation, national, com...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[reserve, speaker]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[reserve, speaker]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[high, education, prevent, veteran, contributi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  PassH\n",
       "0  [implementation, recommendation, national, com...      1\n",
       "1  [implementation, recommendation, national, com...      1\n",
       "2                                 [reserve, speaker]      0\n",
       "3                                 [reserve, speaker]      0\n",
       "4  [high, education, prevent, veteran, contributi...      0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['Title'] = df['Title'].apply(tokenizer)\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Train and Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['Title']\n",
    "y = df['PassH']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    To provide for the implementation of the recom...\n",
       "1                                Reserved for Speaker.\n",
       "2    To amend the Higher Education Act of 1965 to p...\n",
       "3    To award a congressional gold medal to Edward ...\n",
       "4    To amend the Haitian Hemispheric Opportunity t...\n",
       "Name: Title, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modeling**\n",
    "\n",
    "Import packages:\n",
    "\n",
    "- CountVectorizer\n",
    "- TFIDF\n",
    "\n",
    "- Naive Bayes\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "\n",
    "**Remember to look at feature importances!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "# We will train our classifier with the following features:\n",
    "\n",
    "# We create the preprocessing pipelines for all data types.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test split!\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10214,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40853,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sentence Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer\n",
    "# model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence_embeddings_train = model.encode(X_train)\n",
    "# sentence_embeddings_test = model.encode(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_single_pred = nb.predict(['A bill to make all healthcare free and designate waterways in Arkansas as regulated and provide.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_single_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1, 'Confusion Matrix')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# #shows percent data represented in each quadrant\n",
    "\n",
    "# sns.heatmap(nb_confusion_matrix/np.sum(nb_confusion_matrix), annot=True, \n",
    "#             fmt='.2%', cmap='Blues')\n",
    "\n",
    "# plt.ylabel('True Label')\n",
    "# plt.xlabel('Predicted Label')\n",
    "# plt.title('Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Pipeline or DFMapper!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**\n",
    "\n",
    "- Precision means the percentage of your results which are relevant. \n",
    "- recall refers to the percentage of total relevant results correctly classified by your algorithm.\n",
    "\n",
    "Also make a precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer = tokenizer, max_df = 0.90, max_features = 10000) # max_df=0.90, min_df=10\n",
    "transformed = vectorizer.fit_transform(X_train, y_train)\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "\n",
    "# vectorizer = CountVectorizer(tokenizer=tokenizer, max_df=0.5, max_features=None)\n",
    "\n",
    "# transformed = c_vectorizer.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#is it vectorizer or transformed?\n",
    "filename = 'finalized_countvectorizer_WORDSONLY.sav'\n",
    "pickle.dump(transformed, open(filename, 'wb'))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melissamunz/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15621  3162]\n",
      " [  352  1292]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.83      0.90     18783\n",
      "           1       0.29      0.79      0.42      1644\n",
      "\n",
      "    accuracy                           0.83     20427\n",
      "   macro avg       0.63      0.81      0.66     20427\n",
      "weighted avg       0.92      0.83      0.86     20427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Bring in OHE?\n",
    "\n",
    "lr_clf = Pipeline([('vect', CountVectorizer(tokenizer=tokenizer, max_df=0.5, max_features=None)),\n",
    "               ('clf', LogisticRegression(class_weight='balanced', C=.8)),\n",
    "              ])\n",
    "\n",
    "# Logistic Regression Classifier\n",
    "\n",
    "lr_clf = LogisticRegression(class_weight='balanced', C=.8)\n",
    "\n",
    "lr_clf.fit(transformed)\n",
    "\n",
    "lr_y_pred = lr_clf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, lr_y_pred))\n",
    "print(classification_report(y_test, lr_y_pred))\n",
    "\n",
    "lr_confusion_matrix = confusion_matrix(y_test, lr_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <function tokenizer at 0x124382158>: it's not the same object as __main__.tokenizer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-51114e8776e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# save the model to disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'finalized_logistic_regression_word_model.sav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# some time later...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <function tokenizer at 0x124382158>: it's not the same object as __main__.tokenizer"
     ]
    }
   ],
   "source": [
    "# save the model to disk\n",
    "filename2 = 'finalized_logistic_regression_word_model.sav'\n",
    "pickle.dump(lr_clf, open(filename2, 'wb'))\n",
    " \n",
    "# some time later...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "lr_clf_model = pickle.load(open(filename2, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ = lr_clf_model.predict(['A bill to provide tax releif and tax incentives and jobs and reduce recidivism'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15223  3560]\n",
      " [  388  1256]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.81      0.89     18783\n",
      "           1       0.26      0.76      0.39      1644\n",
      "\n",
      "    accuracy                           0.81     20427\n",
      "   macro avg       0.62      0.79      0.64     20427\n",
      "weighted avg       0.92      0.81      0.85     20427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Bring in OHE?\n",
    "\n",
    "lr_clf_tf = Pipeline([('vect', TfidfVectorizer(tokenizer=tokenizer)),\n",
    "               ('clf', LogisticRegression(class_weight='balanced', C=.8)),\n",
    "              ])\n",
    "\n",
    "# Logistic Regression Classifier\n",
    "# lr_classifier = LogisticRegression()\n",
    "\n",
    "lr_clf_tf.fit(X_train, y_train)\n",
    "\n",
    "lr_y_pred_tf = lr_clf_tf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, lr_y_pred_tf))\n",
    "print(classification_report(y_test, lr_y_pred_tf))\n",
    "\n",
    "lr_confusion_matrix = confusion_matrix(y_test, lr_y_pred_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2 = lr_clf_tf.predict(['A bill to provide forests with veterans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1, 'Confusion Matrix')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#shows percent data represented in each quadrant\n",
    "\n",
    "sns.heatmap(lr_confusion_matrix/np.sum(lr_confusion_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')\n",
    "\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for ROC/AUC Curve\n",
    "\n",
    "lr_dec = lr_clf.decision_function(X_test)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "lr_roc_auc = roc_auc_score(y_test, lr_y_pred)\n",
    "lr_roc_auc\n",
    "\n",
    "#This is a decent ROC Score. Remember lays between .5 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "test_fpr, test_tpr, test_thresholds = roc_curve(y_test, lr_dec)\n",
    "\n",
    "print('Test AUC: {}'.format(auc(test_fpr, test_tpr)))\n",
    "\n",
    "# Seaborn's beautiful styling\n",
    "sns.set_style('darkgrid', {'axes.facecolor': '0.9'})\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "lw = 2\n",
    "\n",
    "plt.plot(test_fpr, test_tpr, color='darkorange',\n",
    "         lw=lw, label='Test ROC curve')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.yticks([i/20.0 for i in range(21)])\n",
    "plt.xticks([i/20.0 for i in range(21)])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('(ROC) Curve - Logistic Regression')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "lr_average_precision = average_precision_score(y_test, lr_dec)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      lr_average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "disp = plot_precision_recall_curve(lr_clf, X_test, y_test)\n",
    "disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(lr_average_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate:\n",
    "- ROC/AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**\n",
    "\n",
    "Class Imbalance: To overcome this issue, we used repeated random sub-sampling. Initially, we construct the testing data and the NoS training data sub-samples. For each disease, we train NoS classifiers and test all of them on the same data set. The final labels of the testing data are computed using a majority voting scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#add bag of trees?\n",
    "#add OHE\n",
    "\n",
    "rf_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RandomForestClassifier(max_depth=None, max_features='auto', n_estimators=10, class_weight=\"balanced\"))])\n",
    "\n",
    "\n",
    "rf_pipeline.fit(X_train, y_train) \n",
    "\n",
    "rf_y_pred = rf_pipeline.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, rf_y_pred))\n",
    "print(classification_report(y_test, rf_y_pred))\n",
    "\n",
    "rf_confusion_matrix = confusion_matrix(y_test, rf_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#shows percent data represented in each quadrant\n",
    "\n",
    "sns.heatmap(rf_confusion_matrix/np.sum(rf_confusion_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')\n",
    "\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = rf_pipeline.named_steps['preprocessor'].transformers_[1][1]\\\n",
    "   .named_steps['onehot'].get_feature_names(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf_pipeline.steps[1][1].feature_importances_\n",
    "len(importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(importances)[::-1]\n",
    "top_k = 10\n",
    "new_indices = indices[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_feature_importances(model):\n",
    "    \n",
    "#     n_features = importances.shape\n",
    "    \n",
    "    plt.figure(figsize=(15,200))\n",
    "    plt.barh(range(1044), importances, align='center') \n",
    "    \n",
    "    plt.yticks(np.arange(1044), feature_names) \n",
    "    plt.xlabel('Feature importance')\n",
    "    plt.ylabel('Feature')\n",
    "\n",
    "plot_feature_importances(rf_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Further review of Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FINAL MODEL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Further Evaluation**:\n",
    "- Classification Report\n",
    "- Confusion Matrix\n",
    "- ROC/AUC\n",
    "\n",
    "https://www.kaggle.com/selener/multi-class-text-classification-tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty Confusion Matrix - need to change for each model\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.heatmap(conf_mat, annot=True, cmap=\"Blues\", fmt='d',\n",
    "            xticklabels=category_id_df.Product.values, \n",
    "            yticklabels=category_id_df.Product.values)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title(\"CONFUSION MATRIX - LinearSVC\\n\", size=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing all Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "# 5 Cross-validation\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "\n",
    "entries = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "    \n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_accuracy = cv_df.groupby('model_name').accuracy.mean()\n",
    "std_accuracy = cv_df.groupby('model_name').accuracy.std()\n",
    "\n",
    "acc = pd.concat([mean_accuracy, std_accuracy], axis= 1, \n",
    "          ignore_index=True)\n",
    "acc.columns = ['Mean Accuracy', 'Standard deviation']\n",
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
